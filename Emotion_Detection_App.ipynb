{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU9-xuUEx9Xx"
      },
      "source": [
        "# Emotion Detection Using Hugging Face and Gradio\n",
        "\n",
        "- This Jupyter notebook contains the code for the \"Emotion Detection Using Hugging Face and Gradio\" project.\n",
        "- The objective of this project is to:\n",
        "  - Develop an application that detects and classifies emotions in text inputs using a pre-trained model on the Emotion dataset, showcasing the capabilities of Hugging Face models and Gradio interfaces.\n",
        "- The project involves several steps and each step corresponds to a separate section in this Jupyter Notebook:\n",
        "\n",
        "1. Dataset Selection and Exploration\n",
        "2. Model Selection\n",
        "3. Model Fine-tuning\n",
        "4. Model Evaluation\n",
        "5. Upload Model to Hugging Face\n",
        "6. Gradio Interface Development\n",
        "7. Deployment on Hugging Face Spaces\n",
        "\n",
        "- **Refer the [README](/readme.md) for a detailed project overview.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RzYMcD5hgd6"
      },
      "source": [
        "# Environment Setup\n",
        "\n",
        "- The code in this repository can be executed in 3 ways:\n",
        "  - on google colab\n",
        "  - using Python virtual environment\n",
        "  - using VSCode DevContainers\n",
        "- See below detailed steps for each option. But before that I will cover the packages that will be installed as part of the environment setup.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdS2GRkvhE8W"
      },
      "source": [
        "### Google Colab\n",
        "\n",
        "- To run this code using Google Colab, click [this link](https://colab.research.google.com/github/kanad13/Emotion_Detection_App/blob/master/Emotion_Detection_App.ipynb).\n",
        "- Once you have opened this notebook in colab, uncomment the code below and execute it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmTtsHShyXKN",
        "outputId": "245d8320-e503-4a56-9d0b-53719a41ef20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r .devcontainers/requirements.txt (line 1)) (2.19.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r .devcontainers/requirements.txt (line 2)) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r .devcontainers/requirements.txt (line 3)) (3.7.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r .devcontainers/requirements.txt (line 4)) (4.41.2)\n",
            "Requirement already satisfied: IProgress in /usr/local/lib/python3.10/dist-packages (from -r .devcontainers/requirements.txt (line 5)) (0.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r .devcontainers/requirements.txt (line 6)) (0.31.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from -r .devcontainers/requirements.txt (line 7)) (0.23.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (from -r .devcontainers/requirements.txt (line 8)) (4.36.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->-r .devcontainers/requirements.txt (line 1)) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->-r .devcontainers/requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r .devcontainers/requirements.txt (line 1)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r .devcontainers/requirements.txt (line 1)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r .devcontainers/requirements.txt (line 1)) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r .devcontainers/requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r .devcontainers/requirements.txt (line 1)) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r .devcontainers/requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->-r .devcontainers/requirements.txt (line 1)) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r .devcontainers/requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r .devcontainers/requirements.txt (line 1)) (3.9.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->-r .devcontainers/requirements.txt (line 1)) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r .devcontainers/requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r .devcontainers/requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r .devcontainers/requirements.txt (line 2)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r .devcontainers/requirements.txt (line 2)) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r .devcontainers/requirements.txt (line 3)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r .devcontainers/requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r .devcontainers/requirements.txt (line 3)) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r .devcontainers/requirements.txt (line 3)) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r .devcontainers/requirements.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r .devcontainers/requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r .devcontainers/requirements.txt (line 4)) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->-r .devcontainers/requirements.txt (line 4)) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r .devcontainers/requirements.txt (line 4)) (0.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from IProgress->-r .devcontainers/requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r .devcontainers/requirements.txt (line 6)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r .devcontainers/requirements.txt (line 6)) (2.3.0+cu121)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r .devcontainers/requirements.txt (line 7)) (4.12.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (0.111.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==1.0.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (1.0.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (0.27.0)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (3.10.4)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (2.7.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (0.0.9)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (0.4.8)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (0.12.3)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r .devcontainers/requirements.txt (line 8)) (0.30.1)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.1->gradio->-r .devcontainers/requirements.txt (line 8)) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r .devcontainers/requirements.txt (line 8)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r .devcontainers/requirements.txt (line 8)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r .devcontainers/requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r .devcontainers/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r .devcontainers/requirements.txt (line 1)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r .devcontainers/requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r .devcontainers/requirements.txt (line 1)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r .devcontainers/requirements.txt (line 1)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r .devcontainers/requirements.txt (line 1)) (4.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r .devcontainers/requirements.txt (line 8)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r .devcontainers/requirements.txt (line 8)) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r .devcontainers/requirements.txt (line 8)) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r .devcontainers/requirements.txt (line 8)) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r .devcontainers/requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r .devcontainers/requirements.txt (line 8)) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->-r .devcontainers/requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio->-r .devcontainers/requirements.txt (line 8)) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets->-r .devcontainers/requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r .devcontainers/requirements.txt (line 6)) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r .devcontainers/requirements.txt (line 6)) (3.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r .devcontainers/requirements.txt (line 6)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r .devcontainers/requirements.txt (line 6)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r .devcontainers/requirements.txt (line 6)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r .devcontainers/requirements.txt (line 6)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r .devcontainers/requirements.txt (line 6)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r .devcontainers/requirements.txt (line 6)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r .devcontainers/requirements.txt (line 6)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r .devcontainers/requirements.txt (line 6)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r .devcontainers/requirements.txt (line 6)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r .devcontainers/requirements.txt (line 6)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r .devcontainers/requirements.txt (line 6)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r .devcontainers/requirements.txt (line 6)) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate->-r .devcontainers/requirements.txt (line 6)) (12.5.40)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r .devcontainers/requirements.txt (line 8)) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r .devcontainers/requirements.txt (line 8)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r .devcontainers/requirements.txt (line 8)) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio->-r .devcontainers/requirements.txt (line 8)) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio->-r .devcontainers/requirements.txt (line 8)) (0.0.4)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio->-r .devcontainers/requirements.txt (line 8)) (5.10.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio->-r .devcontainers/requirements.txt (line 8)) (2.1.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->gradio->-r .devcontainers/requirements.txt (line 8)) (2.6.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r .devcontainers/requirements.txt (line 8)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r .devcontainers/requirements.txt (line 8)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r .devcontainers/requirements.txt (line 8)) (0.18.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r .devcontainers/requirements.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r .devcontainers/requirements.txt (line 8)) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio->-r .devcontainers/requirements.txt (line 8)) (1.2.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio->-r .devcontainers/requirements.txt (line 8)) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio->-r .devcontainers/requirements.txt (line 8)) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio->-r .devcontainers/requirements.txt (line 8)) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio->-r .devcontainers/requirements.txt (line 8)) (0.22.0)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate->-r .devcontainers/requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r .devcontainers/requirements.txt (line 8)) (0.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "PyTorch version: 2.3.0+cu121\n",
            "Torchvision version: 0.18.0+cu121\n",
            "Torchaudio version: 2.3.0+cu121\n"
          ]
        }
      ],
      "source": [
        "# Install pandas and other packages\n",
        "!pip3 install -r requirements.txt\n",
        "\n",
        "# Install PyTorch and related packages separately (on colab)\n",
        "%pip install torch torchvision torchaudio\n",
        "\n",
        "# Comment above line when running on Apple Silicon. It is for Google Colab.\n",
        "# Uncomment below line when running on Apple Silicon - https://developer.apple.com/metal/pytorch/\n",
        "# !pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu\n",
        "\n",
        "# Verify the installation by importing the libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchaudio\n",
        "import accelerate\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"Torchvision version:\", torchvision.__version__)\n",
        "print(\"Torchaudio version:\", torchaudio.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw3J1TXpx9X1"
      },
      "source": [
        "### Python virtual environment\n",
        "\n",
        "- All packages needed for running this code can be deployed inside a virtual environment\n",
        "- These are the steps\n",
        "  - First clone this repo locally\n",
        "  - Then open the folder\n",
        "    - `cd emotion_detection`\n",
        "- Then create a Python virtual environment\n",
        "  - `python -m venv emotion_detection_venv`\n",
        "- Then activate the virtual environment\n",
        "  - On windows - `.\\emotion_detection_venv\\Scripts\\activate`\n",
        "  - On mac - `source emotion_detection_venv/bin/activate`\n",
        "  - And now install all dependencies\n",
        "    - `pip install -r requirements.txt`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9lttW2Zx9X1"
      },
      "source": [
        "### VSCode DevContainers\n",
        "\n",
        "- If you use [vscode devcontainers](https://code.visualstudio.com/docs/devcontainers/containers) like me, then you dont have to do anything noted above in the python virtual env section\n",
        "- I have setup the repo nicely to be launch-ready the moment you download it\n",
        "- Launch vscode, and then open the command palette (ctrl+shift+p), and then select \"Remote-Containers: Open Folder in Container\"\n",
        "- Navigate to the cloned repository folder and bam...you are done...all requirements will be automatically installed\n",
        "- You can also make modifications to these 2 files as needed\n",
        "  - [devcontainer.json](.devcontainer/devcontainer.json)\n",
        "  - [postStart.sh](.devcontainer/postStart.sh)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHjDWfLVhgd9"
      },
      "source": [
        "## Optional - Run Gradio locally\n",
        "\n",
        "- I have developed the UI for the app using Gradio. To use it locally, execute the following command:\n",
        "\n",
        "```bash\n",
        "python app.py\n",
        "```\n",
        "\n",
        "- The app will be accessible at `http://localhost:7860`.\n",
        "- When using Google Colab, the gradio will be rendered directly inside the Notebook; so you dont need to open it separately.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zcEQrOzhgd-"
      },
      "source": [
        "## Packages Installed\n",
        "\n",
        "- **File location**\n",
        "  - I have put all these packages in [requirements.txt](.devcontainer/requirements.txt)\n",
        "- **Pandas**\n",
        "  - It is the most popular data manipulation and analysis library for Python.\n",
        "  - I started my Python journey with Pandas. ;) And I believe that is the case for many others.\n",
        "  - It provides data structures like DataFrame and Series, and functions for reading, writing, and transforming data.\n",
        "- **Matplotlib**\n",
        "  - I have used this library in my code for generating plots.\n",
        "  - It can also be used for plotting histograms, bar charts, and other types of graphs to visualize data.\n",
        "- **IProgress**\n",
        "  - Ideally this library need not be explicitly installed. But I keep on getting errors when it is not installed. So I have included it.\n",
        "  - It provides interactive progress bars for Jupyter Notebooks.\n",
        "- **Datasets**\n",
        "  - It is a library by Hugging Face to access datasets.\n",
        "  - It allows for easy dataset loading, preprocessing, and sharing.\n",
        "- **Accelerate**\n",
        "  - Yet another library by Hugging Face\n",
        "  - It simplifies the process of training and deploying machine learning models across different hardware configurations.\n",
        "- **Transformers**\n",
        "  - This is another library by Hugging Face.\n",
        "  - It provides pre-trained models for NLP. I have used one of them in this code viz. DistilBERT\n",
        "- **Hugging Face Hub**\n",
        "  - `huggingface_hub` allows interaction with the Hugging Face Hub.\n",
        "  - Hugging Face Hub is a platform for sharing and collaborating on machine learning models and datasets.\n",
        "  - `huggingface_hub` helps with tasks like uploading, downloading, and managing models and datasets.\n",
        "- **Gradio**\n",
        "  - It is an open-source Python library.\n",
        "  - It allows you to quickly create customizable user interfaces for machine learning models.\n",
        "  - I have created the UI for my Emotion Detection App using gradio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm4tB6zBhgd-"
      },
      "source": [
        "# Step 1 - Dataset Selection and Exploration\n",
        "\n",
        "- The \"Emotion Detection App\" involves several steps and each step corresponds to a separate section in this Jupyter Notebook:\n",
        "\n",
        "1. Dataset Selection and Exploration - `covered in this section`\n",
        "2. Model Selection\n",
        "3. Model Fine-tuning\n",
        "4. Model Evaluation\n",
        "5. Upload Model to Hugging Face\n",
        "6. Gradio Interface Development\n",
        "7. Deployment on Hugging Face Spaces\n",
        "\n",
        "- In this section, I cover the first step of the \"Emotion Detection in Text Using Hugging Face and Gradio\" project.\n",
        "- The steps covered are\n",
        "  - Use the Emotion dataset available on Hugging Face.\n",
        "  - Explore the dataset to understand its structure, including the different classes of emotions (e.g., joy, anger, sadness, etc.).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRtOTgMnhgd-"
      },
      "source": [
        "## About the Emotion Dataset\n",
        "\n",
        "- Emotion is a dataset of English Twitter messages with six basic emotions: anger, fear, joy, love, sadness, and surprise.\n",
        "- For more detailed information please refer to the [dataset](https://huggingface.co/datasets/dair-ai/emotion)\n",
        "- The data fields are:\n",
        "  - `text`: a string feature\n",
        "  - `label`: a classification label, with possible values including sadness (0), joy (1), love (2), anger (3), fear (4), surprise (5)\n",
        "- An example looks as follows.\n",
        "\n",
        "```json\n",
        "{\n",
        "\t\"text\": \"im feeling quite sad and sorry for myself but ill snap out of it soon\",\n",
        "\t\"label\": 0\n",
        "}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcm8R9Mgx9X2"
      },
      "source": [
        "## Importing Emotion Dataset\n",
        "\n",
        "- In this section I will import the dataset and explore its structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8ElvDlrx9X3",
        "outputId": "119e798b-63ca-4ca7-9e35-0be0a2faa418"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 16000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Import dataset\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings about logging to Hugging Face, since I plan to only use public datasets.\n",
        "warnings.filterwarnings(\"ignore\", message=\"The secret `HF_TOKEN` does not exist\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"The repository for emotion contains custom code\")\n",
        "\n",
        "# Load the Emotion dataset with trust_remote_code parameter\n",
        "emotion_dataset = load_dataset(\"emotion\", trust_remote_code=True)\n",
        "\n",
        "# Display the dataset structure\n",
        "print(emotion_dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MBl8p0sx9X4"
      },
      "source": [
        "## Exploring the Dataset\n",
        "\n",
        "- To understand the dataset, I will now explore the different splits (train, validation, test) and the class distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIKIarB6x9X4",
        "outputId": "ca9c4d8b-eee0-4b7c-f8aa-a35ef58e1c20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text  label\n",
            "0                            i didnt feel humiliated      0\n",
            "1  i can go from feeling so hopeless to so damned...      0\n",
            "2   im grabbing a minute to post i feel greedy wrong      3\n",
            "3  i am ever feeling nostalgic about the fireplac...      2\n",
            "4                               i am feeling grouchy      3\n",
            "              label\n",
            "count  16000.000000\n",
            "mean       1.565937\n",
            "std        1.501430\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        1.000000\n",
            "75%        3.000000\n",
            "max        5.000000\n",
            "label\n",
            "1    5362\n",
            "0    4666\n",
            "3    2159\n",
            "4    1937\n",
            "2    1304\n",
            "5     572\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Convert the dataset to Pandas DataFrame for easier exploration\n",
        "train_df = emotion_dataset['train'].to_pandas()\n",
        "validation_df = emotion_dataset['validation'].to_pandas()\n",
        "test_df = emotion_dataset['test'].to_pandas()\n",
        "\n",
        "# Display the first few rows of the training dataset\n",
        "print(train_df.head())\n",
        "\n",
        "# Display basic statistics\n",
        "print(train_df.describe())\n",
        "\n",
        "# Check the distribution of emotions in the training set\n",
        "print(train_df['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJLwJ-nHx9X5"
      },
      "source": [
        "## Visualizing the Class Distribution\n",
        "\n",
        "- To visualize the class distribution, we'll plot the counts of each emotion class in the training dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "3kr91ycbx9X5",
        "outputId": "eb9f363b-95f6-40b5-dd5c-192871aeae16"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define emotion labels\n",
        "emotion_labels = emotion_dataset['train'].features['label'].names\n",
        "\n",
        "# Plot the distribution of emotions in the training set\n",
        "train_df['label'].value_counts().plot(kind='bar', color='skyblue')\n",
        "plt.xlabel('Emotion')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Emotions in the Training Set')\n",
        "plt.xticks(ticks=range(len(emotion_labels)), labels=emotion_labels, rotation=45)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Stf7tc1cx9X5"
      },
      "source": [
        "## Sample Data Inspection\n",
        "\n",
        "- To get a better understanding, let me inspect some sample data points for each emotion class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t90IPPcrx9X5",
        "outputId": "b18ed775-a82a-4100-9149-c35408767cee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Emotion: sadness\n",
            " - i feel remorseful for not making the most with them\n",
            " - i still feel ashamed that i live in a world of people who dont know how\n",
            "Emotion: anger\n",
            " - i sat with dave atell at first trying not to feel rude while the guys were eating\n",
            " - i feel very disgusted by that i cant tolerated her actions anymore by writing this post\n",
            "Emotion: love\n",
            " - i believe is based on greed has nothing to do with how i feel about my beloved country\n",
            " - i had been lying to myself feeling that maybe because i so loved spending time with this fellow and thought he enjoyed his time so equally with me that maybe the ends justified the means\n",
            "Emotion: surprise\n",
            " - i feel amazed i can compress my difficulty so neatly into one sentence\n",
            " - i stood kind of dumbfounded looking around feeling culture shocked\n",
            "Emotion: fear\n",
            " - i take the offense that is most frightening to me when i am feeling the most vulnerable in close relationships with others and i draw that offense and all my frightful vulnerability into the love of god into the mercy seat that fills me full\n",
            " - i no longer feel timid or insecure when i walked\n",
            "Emotion: joy\n",
            " - i feel so blessed now that i think something tragic is going to happen to me in the future huhuhu see i m still battling that thinking positive thing\n",
            " - im a little tired of writing about these things and feel like these solemn posts are a bit too much for this home school family blog\n"
          ]
        }
      ],
      "source": [
        "# Function to print sample texts for each emotion\n",
        "def print_samples(df, num_samples=2):\n",
        "    for label in df['label'].unique():\n",
        "        samples = df[df['label'] == label].sample(num_samples)\n",
        "        emotion = emotion_labels[label]\n",
        "        print(f\"Emotion: {emotion}\")\n",
        "        for text in samples['text']:\n",
        "            print(f\" - {text}\")\n",
        "\n",
        "# Print sample texts\n",
        "print_samples(train_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqctSY8Cx9X6"
      },
      "source": [
        "# Step 2 - Model Selection\n",
        "\n",
        "- The \"Emotion Detection App\" involves several steps and each step corresponds to a separate section in this Jupyter Notebook:\n",
        "\n",
        "1. Dataset Selection and Exploration - `covered in previous section`\n",
        "2. Model Selection - `covered in this section`\n",
        "3. Model Fine-tuning\n",
        "4. Model Evaluation\n",
        "5. Upload Model to Hugging Face\n",
        "6. Gradio Interface Development\n",
        "7. Deployment on Hugging Face Spaces\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p5N5jnrx9X6"
      },
      "source": [
        "## Pre-trained Transformer Model\n",
        "\n",
        "- In this section, I will use the transformers library to select and load a pre-trained model.\n",
        "- For this task, I'll use DistilBERT, a smaller and faster version of BERT that is suitable for text classification tasks.\n",
        "- See in the next sub-section, the details about:\n",
        "  - What are Transformer Models?\n",
        "  - Pre-trained vs. Non-Pre-trained Transformer Models\n",
        "  - Major Pre-trained Transformer Models\n",
        "  - Why Did We Select DistilBERT?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ove01ZKfx9X7"
      },
      "source": [
        "## What are Transformer Models?\n",
        "\n",
        "- Transformer models are a type of neural network architecture designed for handling sequential data, such as text.\n",
        "- The key innovation of transformers is the self-attention mechanism, which allows the model to weigh the importance of different words in a sentence when making predictions, enabling the handling of long-range dependencies more effectively.\n",
        "- Consider the sentence: \"The cat sat on the mat because it was soft.\" A transformer model can understand that \"it\" refers to \"the mat\" because of the self-attention mechanism, which helps the model focus on relevant parts of the sentence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcvF6pskx9X7"
      },
      "source": [
        "## Pre-trained vs. Non-Pre-trained Transformer Models\n",
        "\n",
        "| Feature               | Pre-trained Transformer Models                                                  | Non-Pre-trained Transformer Models                                            |\n",
        "| --------------------- | ------------------------------------------------------------------------------- | ----------------------------------------------------------------------------- |\n",
        "| **Training Time**     | Requires less time as models are pre-trained on large datasets.                 | Requires extensive training time and computational resources.                 |\n",
        "| **Performance**       | Generally achieves higher performance on specific tasks due to prior knowledge. | Performance depends heavily on the quality and quantity of the training data. |\n",
        "| **Data Requirements** | Can work well with smaller labeled datasets.                                    | Requires large amounts of labeled data for training from scratch.             |\n",
        "| **Use Case**          | Ideal for tasks where similar models have been successfully applied.            | Suitable for novel tasks or when custom architecture is required.             |\n",
        "| **Flexibility**       | Limited to the architecture of the pre-trained model.                           | Full control over model architecture and training process.                    |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgCqQCc0x9X7"
      },
      "source": [
        "### Major Pre-trained Transformer Models\n",
        "\n",
        "| Model          | Description                                                                                                                   |\n",
        "| -------------- | ----------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **BERT**       | Bidirectional Encoder Representations from Transformers. Designed for understanding the context of a word in search queries.  |\n",
        "| **RoBERTa**    | Robustly optimized BERT approach. Improves on BERT by training with larger mini-batches and longer sequences.                 |\n",
        "| **DistilBERT** | A smaller, faster, and cheaper version of BERT. Retains 97% of BERT's language understanding capabilities.                    |\n",
        "| **XLNet**      | Combines the best of BERT and autoregressive models like GPT, leading to state-of-the-art performance on many benchmarks.     |\n",
        "| **T5**         | Text-To-Text Transfer Transformer. Frames all NLP tasks as text-to-text problems, enabling a unified approach.                |\n",
        "| **BART**       | Bidirectional and Auto-Regressive Transformers. Combines bidirectional and autoregressive training for text generation tasks. |\n",
        "| **GPT-X**      | Generative Pre-trained Transformer 3, 3.5, 4 or 4-o. Designed for generating human-like text based on input prompts.          |\n",
        "| **Gemini**     | A state-of-the-art model by Google, known for its strong performance in various NLP tasks and advanced capabilities.          |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDxNw0BQx9X7"
      },
      "source": [
        "## Why Did I Select DistilBERT?\n",
        "\n",
        "I selected DistilBERT for the following reasons:\n",
        "\n",
        "1. **Efficiency**: DistilBERT is designed to be smaller, faster, and lighter than BERT, making it more suitable for quick iterations and deployment on less powerful hardware.\n",
        "2. **Performance**: Despite its smaller size, DistilBERT retains 97% of BERT's language understanding capabilities, ensuring high performance in emotion detection tasks.\n",
        "3. **Pre-training**: DistilBERT is pre-trained on large text corpora, allowing it to leverage a rich understanding of language, which is beneficial for tasks like emotion detection with limited labeled data.\n",
        "4. **Community Support**: Being a part of the Hugging Face ecosystem, DistilBERT has extensive community support and pre-built functions for easy implementation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gqUx3lWx9X9"
      },
      "source": [
        "# Step 3 - Model Fine-tuning\n",
        "\n",
        "- The \"Emotion Detection App\" involves several steps and each step corresponds to a separate section in this Jupyter Notebook:\n",
        "\n",
        "1. Dataset Selection and Exploration\n",
        "2. Model Selection - `covered in previous section`\n",
        "3. Model Fine-tuning - `covered in this section`\n",
        "4. Model Evaluation\n",
        "5. Upload Model to Hugging Face\n",
        "6. Gradio Interface Development\n",
        "7. Deployment on Hugging Face Spaces\n",
        "\n",
        "- **Objective of this section**\n",
        "  - Select a pre-trained transformer model suitable for text classification tasks (in our case DistilBERT)\n",
        "  - Fine-tune the selected model on the Emotion dataset to enhance its performance for emotion detection.\n",
        "- **Detailed Steps**\n",
        "  - _Import Required Libraries_\n",
        "    - Install and import the necessary libraries for handling the dataset, model selection, and fine-tuning.\n",
        "  - _Load the Emotion Dataset_\n",
        "    - Use the Hugging Face datasets library to load the Emotion dataset.\n",
        "  - _Choose a Pre-trained Model_\n",
        "    - Select a suitable transformer model from the Hugging Face model hub, such as BERT, RoBERTa, or DistilBERT.\n",
        "  - _Preprocess the Data_\n",
        "    - Tokenize the text data.\n",
        "    - Convert the tokenized inputs into a format suitable for the model.\n",
        "  - _Loading the Pre-trained Model_\n",
        "    - Define the training parameters and fine-tune the model on the Emotion dataset.\n",
        "  - _Defining Training Arguments_\n",
        "    - Use `training_args`to specify parameters like output directory, number of epochs, batch size, warmup steps, weight decay, logging directory, and logging steps.\n",
        "  - _Defining the Trainer_\n",
        "    - Trainer is a high-level class from Hugging Face that simplifies the training and evaluation process.\n",
        "  - _Fine-tuning the Model_\n",
        "    - Use `trainer.train()`that starts the training process.\n",
        "    - It automatically handles the training loop, including the forward pass, backward pass, and optimization steps.\n",
        "  - _Saving the Model and Tokenizer_\n",
        "    - Save the fine-tuned model & tokenizer to a local directory.\n",
        "    - This ensures that the model and tokenizer can be loaded later for inference or further training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5DionGhty0s"
      },
      "source": [
        "## Choice of input parameters\n",
        "\n",
        "- I have fine-tuned this pre-trained model on colab and also on my Apple Silicon Mac.\n",
        "- Since both of them have constrained resources, I had to ensure that the fine-tuning does not consume too many resources and does not end up being executed for hours.\n",
        "- So, this section explains the choices of training parameter values I made and the reason for them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rfr7BokowJB9"
      },
      "source": [
        "### Size of input dataset\n",
        "\n",
        "- The Emotions Dataset originally contains 16k labelled examples.\n",
        "- My Mac can not handle it. Neither can my colab (yes, I am too poor for colab premium)\n",
        "- So I am using smaller subset of the dataset for faster training, only 5000.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnB7OO7fuxRD"
      },
      "source": [
        "### Training Arguments\n",
        "\n",
        "- See below the training argument values I have set.\n",
        "- I have also described the ideal values for some of them.\n",
        "\n",
        "```python\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=1,              # number of training epochs (ideal value 3)\n",
        "    per_device_train_batch_size=8,   # batch size for training (ideal value 16)\n",
        "    per_device_eval_batch_size=8,    # batch size for evaluation (ideal value 16)\n",
        "    warmup_steps=300,                # number of warmup steps for learning rate scheduler (ideal value 500)\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhljNs4Huirk"
      },
      "source": [
        "### Training Steps\n",
        "\n",
        "- I have not directly specified the training steps in the training arguments as mentioned above.\n",
        "- Instead, it is derived from a combination of factors, including the number of epochs, the size of the dataset, and the batch size\n",
        "- Here is how it is calculated:\n",
        "\n",
        "$$\n",
        "\\text{Total Training Steps} = \\frac{\\text{Number of Training Examples}}{\\text{Batch Size}} \\times \\text{Number of Epochs}\n",
        "$$\n",
        "\n",
        "- Given the values of my Training Arguments as mentioned above\n",
        "\n",
        "$$\n",
        "\\text{Total Training Steps} = \\frac{1000}{8} \\times 1 = 125\n",
        "$$\n",
        "\n",
        "- To summarize, the 125 training steps are a result of the number of examples from the training dataset (1000), the batch size (8), and the number of epochs (1).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245,
          "referenced_widgets": [
            "76e99c8c940e473f9e2481cd7a6af196",
            "daffd17cc11548e680aeb15fe2342fe6",
            "ec9e683e0ac84ad98b22b977a7b5c99f",
            "a00fdfa5e4ca496aa434cab686eb6db1",
            "c9dcce5da95e4ea0ac3ff4a04ef91ca4",
            "f3e5334ac6334769bec43e77884c2835",
            "de7e220a468a40fdadb6c2c66748ae07",
            "2e4d6cff7c6649178354476c86fa2edf",
            "6600f3b00ecb414492a6685a281aa8b8",
            "86f27d0a15c74bc0b2b408ba7f1685cb",
            "7acb2ba9265746d0beab32e99ef272f3"
          ]
        },
        "id": "Dy_eCaQKx9X9",
        "outputId": "ad25b693-c915-4922-b1ba-f7d0bec4ba04"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76e99c8c940e473f9e2481cd7a6af196",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:07, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "('emotion-detection-tokenizer/tokenizer_config.json',\n",
              " 'emotion-detection-tokenizer/special_tokens_map.json',\n",
              " 'emotion-detection-tokenizer/vocab.txt',\n",
              " 'emotion-detection-tokenizer/added_tokens.json',\n",
              " 'emotion-detection-tokenizer/tokenizer.json')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 3 - Model Fine-tuning\n",
        "\n",
        "# Import required libraries\n",
        "from datasets import load_dataset  # to load datasets from Hugging Face Hub\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments  # to use pre-trained models and training utilities\n",
        "import torch  # PyTorch for tensor operations\n",
        "import numpy as np  # for numerical operations\n",
        "\n",
        "# Load the Emotion dataset from the Hugging Face Hub\n",
        "emotion_dataset = load_dataset(\"emotion\", trust_remote_code=True)\n",
        "\n",
        "# Specify the pre-trained model name to be used (DistilBERT)\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "# Load the tokenizer for the specified pre-trained model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)# use force_download=True when needed\n",
        "\n",
        "# Define a function to preprocess the data\n",
        "def preprocess_data(examples):\n",
        "    # Tokenize the input text, truncate to max length, and pad to max length\n",
        "    return tokenizer(examples['text'], truncation=True, padding='max_length')\n",
        "\n",
        "# Take a smaller subset of the training dataset for faster training\n",
        "train_dataset = emotion_dataset['train'].shuffle(seed=42).select(range(10))\n",
        "# Take a smaller subset of the validation dataset for faster evaluation\n",
        "eval_dataset = emotion_dataset['validation'].shuffle(seed=42).select(range(10))\n",
        "\n",
        "# Apply the preprocessing function to the training dataset\n",
        "tokenized_train_dataset = train_dataset.map(preprocess_data, batched=True)\n",
        "# Apply the preprocessing function to the validation dataset\n",
        "tokenized_eval_dataset = eval_dataset.map(preprocess_data, batched=True)\n",
        "\n",
        "# Prepare the dataset for PyTorch by removing the 'text' column\n",
        "tokenized_train_dataset = tokenized_train_dataset.remove_columns(['text'])\n",
        "tokenized_eval_dataset = tokenized_eval_dataset.remove_columns(['text'])\n",
        "# Rename the 'label' column to 'labels' to match the model's expectation\n",
        "tokenized_train_dataset = tokenized_train_dataset.rename_column(\"label\", \"labels\")\n",
        "tokenized_eval_dataset = tokenized_eval_dataset.rename_column(\"label\", \"labels\")\n",
        "# Set the format of the dataset to PyTorch tensors\n",
        "tokenized_train_dataset.set_format('torch')\n",
        "tokenized_eval_dataset.set_format('torch')\n",
        "\n",
        "# Load the pre-trained model for sequence classification with 6 output labels (emotions)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6)\n",
        "\n",
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # Directory to save the model and logs\n",
        "    num_train_epochs=1,              # Number of training epochs (ideal value 3)\n",
        "    per_device_train_batch_size=8,   # Batch size for training (ideal value 16)\n",
        "    per_device_eval_batch_size=8,    # Batch size for evaluation (ideal value 16)\n",
        "    warmup_steps=50,                # Number of warmup steps for learning rate scheduler (ideal value 500)\n",
        "    weight_decay=0.01,               # Strength of weight decay for regularization\n",
        "    logging_dir='./logs',            # Directory to store logs\n",
        "    logging_steps=10,                # Log every 10 steps\n",
        ")\n",
        "\n",
        "# Instantiate the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # The pre-trained model to be fine-tuned\n",
        "    args=training_args,                  # The training arguments\n",
        "    train_dataset=tokenized_train_dataset,  # The preprocessed training dataset\n",
        "    eval_dataset=tokenized_eval_dataset     # The preprocessed evaluation dataset\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model and tokenizer to disk\n",
        "model.save_pretrained(\"emotion-detection-model\")\n",
        "tokenizer.save_pretrained(\"emotion-detection-tokenizer\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3FGrTijDoy2"
      },
      "source": [
        "# Step 4 - Model Evaluation\n",
        "\n",
        "- The \"Emotion Detection App\" involves several steps and each step corresponds to a separate section in this Jupyter Notebook:\n",
        "\n",
        "1. Dataset Selection and Exploration\n",
        "2. Model Selection\n",
        "3. Model Fine-tuning - `covered in previous section`\n",
        "4. Model Evaluation - `covered in this section`\n",
        "5. Upload Model to Hugging Face\n",
        "6. Gradio Interface Development\n",
        "7. Deployment on Hugging Face Spaces\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9ST0gm2ZnH1"
      },
      "source": [
        "## Recap steps 1 to 3\n",
        "\n",
        "- Let me provide some detailed comments on what has each of the 3 steps achieved earlier:\n",
        "\n",
        "1. **Dataset Selection and Exploration**\n",
        "\n",
        "- I am working with the Emotion dataset from Hugging Face, which contains text inputs labeled with different emotions.\n",
        "  We explored the dataset to understand its structure and the distribution of different emotion classes.\n",
        "\n",
        "2. **Model Selection**\n",
        "\n",
        "- Then I selected a pre-trained model suitable for sequence classification tasks from Hugging Face's model hub.\n",
        "\n",
        "3. **Model Fine-tuning**\n",
        "\n",
        "- Then I fine-tuned the pre-trained model on our Emotion dataset to adapt it specifically for emotion detection in text.\n",
        "\n",
        "The code in the next cell aims to evaluate the fine-tuned model on a test set to measure its performance.\n",
        "\n",
        "I will load the saved model and tokenizer, preprocess the test data, and then use the model to make predictions.\n",
        "\n",
        "Finally, I will calculate and display the accuracy of the model on the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "15W6laXnDq2J",
        "outputId": "da75f734-6a6d-41e7-dac4-39b27d374555"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation result: {'eval_loss': 1.7931840419769287, 'eval_runtime': 9.4857, 'eval_samples_per_second': 1.054, 'eval_steps_per_second': 0.211, 'epoch': 1.0}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     sadness       0.00      0.00      0.00         1\n",
            "         joy       0.00      0.00      0.00         4\n",
            "        love       0.00      0.00      0.00         1\n",
            "       anger       0.00      0.00      0.00         1\n",
            "        fear       0.22      1.00      0.36         2\n",
            "    surprise       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.20        10\n",
            "   macro avg       0.04      0.17      0.06        10\n",
            "weighted avg       0.04      0.20      0.07        10\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to compute metrics\n",
        "def compute_metrics(p):\n",
        "    # Unpack predictions and true labels\n",
        "    predictions, labels = p\n",
        "    # Get the predicted class by finding the index with the highest probability\n",
        "    # The `predictions` object holds the raw predictions and true labels. We use `np.argmax` to get the predicted class with the highest probability.\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    # Calculate accuracy\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    # Generate a detailed classification report\n",
        "    report = classification_report(labels, predictions, target_names=emotion_labels)\n",
        "    return {\"accuracy\": acc, \"report\": report}\n",
        "\n",
        "\n",
        "# Evaluate the model on the evaluation dataset\n",
        "eval_result = trainer.evaluate()\n",
        "print(f\"Evaluation result: {eval_result}\")\n",
        "\n",
        "# Predict on the evaluation dataset\n",
        "predictions = trainer.predict(tokenized_eval_dataset)\n",
        "\n",
        "# Get the predicted class for each sample\n",
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# Generate and print the classification report\n",
        "report = classification_report(predictions.label_ids, preds, target_names=emotion_labels)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJyPe2iOPptk"
      },
      "source": [
        "## Interpret evaluation metrics\n",
        "\n",
        "- The code cell above prints evaluation metrics and the classification report.\n",
        "- Here are some pointers towards understanding this report:\n",
        "\n",
        "1. **Evaluation Loss**:\n",
        "\n",
        "   - `eval_loss`\n",
        "   - It contains the evaluation loss and other metrics, which we print to get a sense of model performance.\n",
        "\n",
        "2. **Evaluation Runtime**:\n",
        "\n",
        "   - `eval_runtime`\n",
        "   - This is the time taken to evaluate the model.\n",
        "\n",
        "3. **Evaluation Speed**:\n",
        "\n",
        "   - `eval_samples_per_second`\n",
        "   - `eval_steps_per_second`\n",
        "   - These metrics indicate the speed of evaluation.\n",
        "\n",
        "4. **Training Parameters**:\n",
        "\n",
        "   - `epoch`\n",
        "   - I had specified this value in Step 3.\n",
        "\n",
        "5. **Classification Report**:\n",
        "   - The classification report provides a more detailed view of the model's performance on a per-class basis.\n",
        "   - `precision`, `recall`, and `f1-score` are metrics that indicate how well the model is performing for each class (sadness, joy, etc.).\n",
        "   - Higher values indicate better quality of the fine-tuned model.\n",
        "   - The table also lists overall accuracy. It indicates e.g. the model is correctly predicting 98% of the samples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJXMy3WeZtNm"
      },
      "source": [
        "# Step 5 - Upload Model to Hugging Face\n",
        "\n",
        "- The \"Emotion Detection App\" involves several steps and each step corresponds to a separate section in this Jupyter Notebook:\n",
        "\n",
        "1. Dataset Selection and Exploration\n",
        "2. Model Selection\n",
        "3. Model Fine-tuning\n",
        "4. Model Evaluation - `covered in previous section`\n",
        "5. Upload Model to Hugging Face - `covered in this section`\n",
        "6. Gradio Interface Development\n",
        "7. Deployment on Hugging Face Spaces\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asf-BO12X5ok"
      },
      "source": [
        "## Hugging Face Token\n",
        "\n",
        "- I will now log in to my Hugging Face account and secure a token as described [here](https://huggingface.co/docs/hub/en/security-tokens).\n",
        "- This token should not be disclosed to anyone.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvPCgRbdXBAy",
        "outputId": "47700a68-6950-4cf3-db0d-17adfad15b20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "# hugging face token\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Replace 'YOUR_HUGGING_FACE_TOKEN' with your actual token\n",
        "login(token=\"YOUR_HUGGING_FACE_TOKEN\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFoYXCQra-cs"
      },
      "source": [
        "## Hugging Face Repository\n",
        "\n",
        "- Now I will create a repository on Hugging Face to store my model.\n",
        "- Replace the repo_name value with your repository name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "-Ez7BriSYO6z",
        "outputId": "66a10629-ad5f-4a28-d6e1-5bf0cf1108ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repository 'kanad13/emotion_detection' does not exist. Proceeding to create a new one.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "RepoUrl('https://huggingface.co/kanad13/emotion_detection', endpoint='https://huggingface.co', repo_type='model', repo_id='kanad13/emotion_detection')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from huggingface_hub import HfApi\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "# Replace 'your-username' and 'new-model-repo' with your actual username and desired repository name\n",
        "repo_owner = \"kanad13\"\n",
        "repo_name = \"emotion_detection\"\n",
        "repo_id = f\"{repo_owner}/{repo_name}\"\n",
        "\n",
        "# Check if the repository exists\n",
        "try:\n",
        "    # Get the repository information\n",
        "    repo_info = api.repo_info(repo_id)\n",
        "    if repo_info:\n",
        "        # If the repository exists, delete it\n",
        "        api.delete_repo(repo_id)\n",
        "        print(f\"Repository '{repo_id}' exists and has been deleted.\")\n",
        "except Exception as e:\n",
        "    # If the repository does not exist, an exception will be raised\n",
        "    print(f\"Repository '{repo_id}' does not exist. Proceeding to create a new one.\")\n",
        "\n",
        "# Create a new repository\n",
        "api.create_repo(repo_id=repo_id)  # Set private=True if you want a private repository\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NKfOFwabcaQ"
      },
      "source": [
        "## Upload Model to Repo\n",
        "\n",
        "- I am now logged into my Hugging Face account. And a new repository is also created.\n",
        "- I will now push the fine-tuned model, tokenizer, and configuration files to my repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "d2f9a23b38c4486fbb6986157b38c978",
            "69322509686045f098d2748b3ece163e",
            "1e9a8795854e4d9ea2dff92c72aed44f",
            "62b65e45b6104f95803f05167cddcb2c",
            "7a190b4620d54dbc857239bd969c2280",
            "310fe31421694677af3d6d5a25a9088a",
            "1f98388e12384d719f165e363c74cf7c",
            "5dccd6d6a67a4746972fe471b27b7ae9",
            "1de7c1d70d7d48a99ea2418649d6bd2d",
            "9181f25409314cb8aa3fcfe508406001",
            "ab1fcec68467427f9793686665c5b515"
          ]
        },
        "id": "dcz0bbnwXOyQ",
        "outputId": "bb5febd2-7d96-4a4f-f4f5-6528d681411f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2f9a23b38c4486fbb6986157b38c978",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/kanad13/emotion_detection/commit/8680efa65a6515fed243bb5d6c0999ba22591497', commit_message='Upload folder using huggingface_hub', commit_description='', oid='8680efa65a6515fed243bb5d6c0999ba22591497', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# upload model to repo\n",
        "\n",
        "from huggingface_hub import upload_folder\n",
        "\n",
        "# Upload the model directory\n",
        "upload_folder(\n",
        "    folder_path=\"emotion-detection-model\",\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"model\"\n",
        ")\n",
        "\n",
        "# Upload the tokenizer directory\n",
        "upload_folder(\n",
        "    folder_path=\"emotion-detection-tokenizer\",\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"model\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjP6vCZMeg51"
      },
      "source": [
        "# Step 6 - Gradio Interface Development\n",
        "\n",
        "- The \"Emotion Detection App\" involves several steps and each step corresponds to a separate section in this Jupyter Notebook:\n",
        "\n",
        "1. Dataset Selection and Exploration\n",
        "2. Model Selection\n",
        "3. Model Fine-tuning\n",
        "4. Model Evaluation\n",
        "5. Upload Model to Hugging Face - `covered in previous section`\n",
        "6. Gradio Interface Development - `covered in this section`\n",
        "7. Deployment on Hugging Face Spaces\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqtQfmqYBQ9z"
      },
      "source": [
        "## Recap steps 1 to 5\n",
        "\n",
        "- Let me provide some detailed comments on what has each of the 5 steps achieved earlier:\n",
        "\n",
        "1. **Dataset Selection and Exploration**\n",
        "\n",
        "- I am working with the Emotion dataset from Hugging Face, which contains text inputs labeled with different emotions.\n",
        "- I explored the dataset to understand its structure and the distribution of different emotion classes.\n",
        "\n",
        "2. **Model Selection**\n",
        "\n",
        "- Then I selected a pre-trained model suitable for sequence classification tasks from Hugging Face's model hub.\n",
        "\n",
        "3. **Model Fine-tuning**\n",
        "\n",
        "- Then I fine-tuned the pre-trained model on our Emotion dataset to adapt it specifically for emotion detection in text.\n",
        "\n",
        "4. **Model Evaluation**\n",
        "\n",
        "   - I then evaluated the model for accuracy and precision.\n",
        "   - The results were in-line with my expectations.\n",
        "   - So I proceeded with uploading the model to Hugging Face\n",
        "\n",
        "5. **Upload Model to Hugging Face**\n",
        "\n",
        "   - In this section, I uploaded the fine-tuned and evaluated model to Hugging Face.\n",
        "   - I used the Hugging Face CLI so that I dont have to leave my Jupyter Notebook to do any manual steps.\n",
        "\n",
        "6. **Gradio Interface Development**\n",
        "\n",
        "   - This is the step now covered in this section.\n",
        "   - It involves developing a Gradio interface that will act as my UI for the model fine-tuned in previous steps.\n",
        "   - It is a simple interface that has just 2 boxes - one to put in your text and another to display the emotion as inferred by the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "cQp_rgoxez7l",
        "outputId": "0ddc687d-3ed2-4fa9-e893-9f9b480647e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://15d9b83238b77c450d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://15d9b83238b77c450d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 6 - Gradio Interface Development\n",
        "\n",
        "import gradio as gr\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"emotion-detection-model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emotion-detection-tokenizer\")\n",
        "\n",
        "# Define emotion labels\n",
        "emotion_labels = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
        "\n",
        "# Define a function to classify emotions in text\n",
        "def classify_emotion(text):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n",
        "    # Get model predictions\n",
        "    outputs = model(**inputs)\n",
        "    # Get the predicted class with the highest probability\n",
        "    predictions = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "    predicted_class = torch.argmax(predictions, dim=1).item()\n",
        "    # Get the predicted emotion label\n",
        "    predicted_emotion = emotion_labels[predicted_class]\n",
        "    return predicted_emotion\n",
        "\n",
        "# Link to my blog post\n",
        "blog_link = \"For more details about this project, visit my [blog post](https://www.kunal-pathak.com/blog/EmotionDetectionApp/).\"\n",
        "\n",
        "\n",
        "# Create a Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=classify_emotion,  # The function to call for predictions\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter text here...\"),  # Input component\n",
        "    outputs=gr.Textbox(),  # Output component\n",
        "    title=\"Emotion Detection in Text\",\n",
        "    description=\"Enter a sentence and the model will predict the emotion.\",\n",
        "    article=blog_link\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface with public sharing enabled\n",
        "interface.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwLyUGgcC56J"
      },
      "source": [
        "# Step 7 - Deployment on Hugging Face Spaces\n",
        "\n",
        "- The \"Emotion Detection App\" involves several steps and each step corresponds to a separate section in this Jupyter Notebook:\n",
        "\n",
        "1. Dataset Selection and Exploration\n",
        "2. Model Selection\n",
        "3. Model Fine-tuning\n",
        "4. Model Evaluation\n",
        "5. Upload Model to Hugging Face\n",
        "6. Gradio Interface Development - `covered in previous section`\n",
        "7. Deployment on Hugging Face Spaces - `covered in this section`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtpIBom9DGJG"
      },
      "source": [
        "## All steps in Jupyter Notebook\n",
        "\n",
        "- Most of the time I go directly to the Hugging Face UI and then create my space and upload the model and do all other activities.\n",
        "- But I want to do the entire operation zero-touch. So the code in the next cell\n",
        "  - Creates the [Hugging Face Space](https://huggingface.co/docs/hub/en/spaces-overview) using the [CLI](https://huggingface.co/docs/huggingface_hub/en/guides/cli).\n",
        "  - Then clones the Space repository to my local/colab environment.\n",
        "  - Copies my Gradio app script, model files, and others dependencies to the cloned repository.\n",
        "  - Commits and pushes the changes to the Space repository, triggering the deployment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy5pXrX8Tg5m",
        "outputId": "b525c9fc-0110-49e3-d8f9-ef74dbb806a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "Cloning into 'emotion-detection'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (4/4), 1.27 KiB | 1.27 MiB/s, done.\n",
            "From https://huggingface.co/spaces/kanad13/emotion-detection\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n",
            "[main 3478922] Add Gradio app script and requirements\n",
            " 2 files changed, 50 insertions(+)\n",
            " create mode 100644 app.py\n",
            " create mode 100644 requirements.txt\n",
            "From https://huggingface.co/spaces/kanad13/emotion-detection\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Current branch main is up to date.\n",
            "Enumerating objects: 5, done.\n",
            "Counting objects: 100% (5/5), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 1.15 KiB | 1.15 MiB/s, done.\n",
            "Total 4 (delta 0), reused 0 (delta 0), pack-reused 0\n",
            "To https://huggingface.co/spaces/kanad13/emotion-detection\n",
            "   69c1824..3478922  main -> main\n"
          ]
        }
      ],
      "source": [
        "# Step 7 - Deployment on Hugging Face Spaces\n",
        "\n",
        "# Import Libraries and Authenticate\n",
        "from huggingface_hub import HfApi, Repository, login\n",
        "import os  # Import the os module here\n",
        "\n",
        "# Authenticate with your Hugging Face token\n",
        "login(token=\"YOUR_HUGGING_FACE_TOKEN\", add_to_git_credential=True)\n",
        "\n",
        "# Create a New Space (skip this if the space already exists)\n",
        "api = HfApi()\n",
        "space_name = \"emotion-detection\"\n",
        "username = \"YOUR_HF_USER_NAME\"  # Replace with your Hugging Face username\n",
        "\n",
        "try:\n",
        "    # Try to create the Space\n",
        "    api.create_repo(repo_id=f\"{username}/{space_name}\", repo_type=\"space\", space_sdk=\"gradio\")\n",
        "except Exception as e:\n",
        "    print(f\"Repository already exists: {e}\")\n",
        "\n",
        "# Remove the local directory if it exists\n",
        "import shutil\n",
        "if os.path.exists(space_name):\n",
        "    shutil.rmtree(space_name)\n",
        "\n",
        "# Clone the Repository with Authentication\n",
        "!git clone https://huggingface.co/spaces/{username}/{space_name}\n",
        "\n",
        "# Change directory to the cloned repo\n",
        "os.chdir(space_name)\n",
        "\n",
        "# Create the Gradio app script and requirements.txt\n",
        "app_code = \"\"\"\n",
        "import gradio as gr\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"kanad13/emotion_detection\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"kanad13/emotion_detection\")\n",
        "\n",
        "# Define emotion labels\n",
        "emotion_labels = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
        "\n",
        "# Define a function to classify emotions in text\n",
        "def classify_emotion(text):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n",
        "    # Get model predictions\n",
        "    outputs = model(**inputs)\n",
        "    # Get the predicted class with the highest probability\n",
        "    predictions = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "    predicted_class = torch.argmax(predictions, dim=1).item()\n",
        "    # Get the predicted emotion label\n",
        "    predicted_emotion = emotion_labels[predicted_class]\n",
        "    return predicted_emotion\n",
        "\n",
        "# Link to my blog post\n",
        "blog_link = \"For more details about this project, visit my [blog post](https://www.kunal-pathak.com/blog/EmotionDetectionApp/).\"\n",
        "\n",
        "# Create a Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=classify_emotion,  # The function to call for predictions\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter text here...\"),  # Input component\n",
        "    outputs=gr.Textbox(),  # Output component\n",
        "    title=\"Emotion Detection in Text\",\n",
        "    description=\"Enter a sentence and the model will predict the emotion.\",\n",
        "    article=blog_link\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "interface.launch()\n",
        "\"\"\"\n",
        "\n",
        "requirements_txt = \"\"\"\n",
        "datasets\n",
        "pandas\n",
        "matplotlib\n",
        "transformers\n",
        "IProgress\n",
        "accelerate\n",
        "huggingface_hub\n",
        "gradio\n",
        "torch\n",
        "\"\"\"\n",
        "\n",
        "# Write the Gradio app script to app.py\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "# Write the requirements.txt\n",
        "with open(\"requirements.txt\", \"w\") as f:\n",
        "    f.write(requirements_txt)\n",
        "\n",
        "# Pull the remote changes to avoid conflicts\n",
        "!git pull origin main\n",
        "\n",
        "# Push the Changes to Hugging Face Spaces\n",
        "!git config --global user.email \"kunalpathak13@gmail.com\"\n",
        "!git config --global user.name \"Kunal Pathak\"\n",
        "\n",
        "!git add app.py requirements.txt\n",
        "!git commit -m \"Add Gradio app script and requirements\"\n",
        "\n",
        "# Pull remote changes to avoid conflicts before pushing\n",
        "!git pull --rebase origin main\n",
        "\n",
        "# Push using the token for authentication\n",
        "!git remote set-url origin https://huggingface.co/spaces/{username}/{space_name}\n",
        "!git push\n",
        "\n",
        "# Navigate back to the original directory\n",
        "os.chdir(\"..\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1de7c1d70d7d48a99ea2418649d6bd2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e9a8795854e4d9ea2dff92c72aed44f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dccd6d6a67a4746972fe471b27b7ae9",
            "max": 267844872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1de7c1d70d7d48a99ea2418649d6bd2d",
            "value": 267844872
          }
        },
        "1f98388e12384d719f165e363c74cf7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e4d6cff7c6649178354476c86fa2edf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "310fe31421694677af3d6d5a25a9088a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dccd6d6a67a4746972fe471b27b7ae9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62b65e45b6104f95803f05167cddcb2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9181f25409314cb8aa3fcfe508406001",
            "placeholder": "",
            "style": "IPY_MODEL_ab1fcec68467427f9793686665c5b515",
            "value": "268M/268M[00:07&lt;00:00,47.2MB/s]"
          }
        },
        "6600f3b00ecb414492a6685a281aa8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69322509686045f098d2748b3ece163e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_310fe31421694677af3d6d5a25a9088a",
            "placeholder": "",
            "style": "IPY_MODEL_1f98388e12384d719f165e363c74cf7c",
            "value": "model.safetensors:100%"
          }
        },
        "76e99c8c940e473f9e2481cd7a6af196": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_daffd17cc11548e680aeb15fe2342fe6",
              "IPY_MODEL_ec9e683e0ac84ad98b22b977a7b5c99f",
              "IPY_MODEL_a00fdfa5e4ca496aa434cab686eb6db1"
            ],
            "layout": "IPY_MODEL_c9dcce5da95e4ea0ac3ff4a04ef91ca4"
          }
        },
        "7a190b4620d54dbc857239bd969c2280": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7acb2ba9265746d0beab32e99ef272f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86f27d0a15c74bc0b2b408ba7f1685cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9181f25409314cb8aa3fcfe508406001": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a00fdfa5e4ca496aa434cab686eb6db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86f27d0a15c74bc0b2b408ba7f1685cb",
            "placeholder": "",
            "style": "IPY_MODEL_7acb2ba9265746d0beab32e99ef272f3",
            "value": "10/10[00:00&lt;00:00,105.37examples/s]"
          }
        },
        "ab1fcec68467427f9793686665c5b515": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9dcce5da95e4ea0ac3ff4a04ef91ca4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2f9a23b38c4486fbb6986157b38c978": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69322509686045f098d2748b3ece163e",
              "IPY_MODEL_1e9a8795854e4d9ea2dff92c72aed44f",
              "IPY_MODEL_62b65e45b6104f95803f05167cddcb2c"
            ],
            "layout": "IPY_MODEL_7a190b4620d54dbc857239bd969c2280"
          }
        },
        "daffd17cc11548e680aeb15fe2342fe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3e5334ac6334769bec43e77884c2835",
            "placeholder": "",
            "style": "IPY_MODEL_de7e220a468a40fdadb6c2c66748ae07",
            "value": "Map:100%"
          }
        },
        "de7e220a468a40fdadb6c2c66748ae07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec9e683e0ac84ad98b22b977a7b5c99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e4d6cff7c6649178354476c86fa2edf",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6600f3b00ecb414492a6685a281aa8b8",
            "value": 10
          }
        },
        "f3e5334ac6334769bec43e77884c2835": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
